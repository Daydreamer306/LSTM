{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a009cd1",
   "metadata": {},
   "source": [
    "# LSTM+Transformer 工业时序预测模型 - PAI-DSW 快速启动\n",
    "\n",
    "本Notebook提供了在PAI-DSW环境中快速部署和运行LSTM+Transformer时序预测模型的完整流程。\n",
    "\n",
    "## 📋 运行环境要求\n",
    "- PAI-DSW实例 (推荐GPU实例)\n",
    "- Python 3.8+\n",
    "- CUDA支持 (推荐)\n",
    "\n",
    "## 🚀 快速开始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a725cc",
   "metadata": {},
   "source": [
    "## 1. 环境初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查当前环境\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"当前工作目录: {os.getcwd()}\")\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "\n",
    "# 设置PAI-DSW环境\n",
    "if os.path.exists('/mnt/workspace'):\n",
    "    os.chdir('/mnt/workspace')\n",
    "    sys.path.insert(0, '/mnt/workspace')\n",
    "    print(\"✅ PAI-DSW环境设置完成\")\n",
    "else:\n",
    "    print(\"⚠️  未检测到PAI-DSW环境，使用当前目录\")\n",
    "\n",
    "print(f\"工作目录: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行完整的环境初始化\n",
    "print(\"🚀 开始环境初始化...\")\n",
    "exec(open('setup_pai_dsw.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11886ad6",
   "metadata": {},
   "source": [
    "## 2. 检查GPU和深度学习环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查PyTorch和CUDA\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU数量: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  显存: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "    # 测试GPU\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.randn(1000, 1000).to(device)\n",
    "    y = torch.randn(1000, 1000).to(device)\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"✅ GPU测试通过\")\n",
    "else:\n",
    "    print(\"⚠️  将使用CPU进行训练\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc96c60",
   "metadata": {},
   "source": [
    "## 3. 数据准备和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f76141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查数据文件\n",
    "import glob\n",
    "\n",
    "print(\"🔍 检查数据文件...\")\n",
    "data_paths = [\n",
    "    'data/raw/*.csv',\n",
    "    'data/*.csv',\n",
    "    '/mnt/workspace/data/*.csv'\n",
    "]\n",
    "\n",
    "data_files = []\n",
    "for path in data_paths:\n",
    "    files = glob.glob(path)\n",
    "    data_files.extend(files)\n",
    "\n",
    "if data_files:\n",
    "    print(\"✅ 发现数据文件:\")\n",
    "    for file in data_files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "    # 显示第一个数据文件的基本信息\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(data_files[0])\n",
    "    print(f\"\\n数据集信息:\")\n",
    "    print(f\"  形状: {df.shape}\")\n",
    "    print(f\"  列名: {list(df.columns)}\")\n",
    "    print(f\"  前5行:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"❌ 未发现数据文件!\")\n",
    "    print(\"请上传CSV格式的训练数据到以下目录之一:\")\n",
    "    print(\"  - data/raw/\")\n",
    "    print(\"  - data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfa8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行数据预处理 (如果数据文件存在)\n",
    "if data_files:\n",
    "    print(\"📊 开始数据预处理...\")\n",
    "    !python src/data/preprocess.py\n",
    "    print(\"✅ 数据预处理完成!\")\n",
    "else:\n",
    "    print(\"⚠️  跳过数据预处理 - 请先上传数据文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b5ac7",
   "metadata": {},
   "source": [
    "## 4. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查配置文件\n",
    "import yaml\n",
    "\n",
    "config_path = 'configs/lstm_transformer.yaml'\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"✅ 配置文件加载成功\")\n",
    "    print(f\"模型配置: {config['model']}\")\n",
    "    print(f\"训练配置: {config['training']}\")\n",
    "else:\n",
    "    print(f\"❌ 配置文件不存在: {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始模型训练 (这可能需要较长时间)\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "if data_files and os.path.exists(config_path):\n",
    "    print(\"🚀 开始模型训练...\")\n",
    "    print(\"注意: 训练可能需要几分钟到几小时，请耐心等待\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 运行训练\n",
    "    result = subprocess.run([\n",
    "        'python', 'src/training/train.py', \n",
    "        '--config', config_path\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"训练耗时: {training_time/60:.1f} 分钟\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ 模型训练完成!\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"❌ 模型训练失败:\")\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print(\"⚠️  跳过模型训练 - 请先完成数据预处理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05061b9d",
   "metadata": {},
   "source": [
    "## 5. 训练进度监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实时查看训练历史\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "history_path = 'results/training_history.json'\n",
    "if os.path.exists(history_path):\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0, 0].set_title('Loss Curves')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # MAE curves\n",
    "    axes[0, 1].plot(history['train_mae'], label='Train MAE')\n",
    "    axes[0, 1].plot(history['val_mae'], label='Val MAE')\n",
    "    axes[0, 1].set_title('MAE Curves')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # R² curves\n",
    "    if 'train_r2' in history:\n",
    "        axes[1, 0].plot(history['train_r2'], label='Train R²')\n",
    "        axes[1, 0].plot(history['val_r2'], label='Val R²')\n",
    "        axes[1, 0].set_title('R² Curves')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning rate\n",
    "    if 'learning_rate' in history:\n",
    "        axes[1, 1].plot(history['learning_rate'], label='Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 显示最佳指标\n",
    "    print(\"🏆 训练结果摘要:\")\n",
    "    print(f\"最终训练Loss: {history['train_loss'][-1]:.6f}\")\n",
    "    print(f\"最终验证Loss: {history['val_loss'][-1]:.6f}\")\n",
    "    print(f\"最佳验证MAE: {min(history['val_mae']):.6f}\")\n",
    "    if 'val_r2' in history:\n",
    "        print(f\"最佳验证R²: {max(history['val_r2']):.6f}\")\n",
    "else:\n",
    "    print(\"⚠️  训练历史文件不存在，请先完成模型训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c2506",
   "metadata": {},
   "source": [
    "## 6. 模型预测和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55209ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查训练好的模型\n",
    "model_path = 'models/best_model.pt'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"✅ 发现训练好的模型: {model_path}\")\n",
    "    \n",
    "    # 显示模型文件信息\n",
    "    model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"模型文件大小: {model_size:.2f} MB\")\n",
    "    \n",
    "    # 加载模型检查点信息\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"训练轮数: {checkpoint['epoch']}\")\n",
    "    if 'val_loss' in checkpoint:\n",
    "        print(f\"验证损失: {checkpoint['val_loss']:.6f}\")\n",
    "    if 'val_mae' in checkpoint:\n",
    "        print(f\"验证MAE: {checkpoint['val_mae']:.6f}\")\n",
    "else:\n",
    "    print(\"❌ 未发现训练好的模型，请先完成模型训练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行模型预测\n",
    "if os.path.exists(model_path):\n",
    "    print(\"🔮 开始模型预测...\")\n",
    "    \n",
    "    !python src/inference/predict.py \\\n",
    "        --config configs/lstm_transformer.yaml \\\n",
    "        --model_path models/best_model.pt \\\n",
    "        --datasets test \\\n",
    "        --generate_viz\n",
    "    \n",
    "    print(\"✅ 模型预测完成!\")\n",
    "else:\n",
    "    print(\"⚠️  跳过模型预测 - 请先完成模型训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea5b90",
   "metadata": {},
   "source": [
    "## 7. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看预测结果可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path('results')\n",
    "if results_dir.exists():\n",
    "    # 查找可视化图片\n",
    "    viz_files = list(results_dir.glob('*.png'))\n",
    "    \n",
    "    if viz_files:\n",
    "        print(f\"📊 发现 {len(viz_files)} 个可视化文件:\")\n",
    "        \n",
    "        # 显示预测结果图\n",
    "        for viz_file in viz_files[:4]:  # 显示前4个图片\n",
    "            print(f\"\\n📈 {viz_file.name}:\")\n",
    "            \n",
    "            try:\n",
    "                from IPython.display import Image, display\n",
    "                display(Image(str(viz_file)))\n",
    "            except:\n",
    "                print(f\"图片路径: {viz_file}\")\n",
    "    else:\n",
    "        print(\"❌ 未发现可视化文件\")\n",
    "else:\n",
    "    print(\"❌ 结果目录不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载并显示预测指标\n",
    "metrics_path = 'results/evaluation_metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"📊 预测评估指标:\")\n",
    "    for dataset_name, dataset_metrics in metrics.items():\n",
    "        print(f\"\\n{dataset_name.upper()} 数据集:\")\n",
    "        for metric_name, value in dataset_metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                if metric_name in ['mape', 'smape']:\n",
    "                    print(f\"  {metric_name.upper()}: {value:.2f}%\")\n",
    "                elif metric_name == 'r2':\n",
    "                    print(f\"  {metric_name.upper()}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {metric_name.upper()}: {value:.6f}\")\n",
    "else:\n",
    "    print(\"⚠️  评估指标文件不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc8b3f",
   "metadata": {},
   "source": [
    "## 8. ONNX模型导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出ONNX模型\n",
    "if os.path.exists(model_path):\n",
    "    print(\"📦 开始ONNX模型导出...\")\n",
    "    \n",
    "    !python src/inference/export_onnx.py \\\n",
    "        --model_path models/best_model.pt \\\n",
    "        --output_path models/model.onnx \\\n",
    "        --batch_size 1 \\\n",
    "        --sequence_length 96 \\\n",
    "        --input_size 1\n",
    "    \n",
    "    # 检查ONNX文件\n",
    "    onnx_path = 'models/model.onnx'\n",
    "    if os.path.exists(onnx_path):\n",
    "        onnx_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "        print(f\"✅ ONNX模型导出成功!\")\n",
    "        print(f\"ONNX文件大小: {onnx_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"❌ ONNX模型导出失败\")\n",
    "else:\n",
    "    print(\"⚠️  跳过ONNX导出 - 请先完成模型训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebb62c",
   "metadata": {},
   "source": [
    "## 9. 项目总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 项目完成度检查\n",
    "print(\"🎯 项目完成度检查:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "checks = [\n",
    "    (\"环境初始化\", os.path.exists('pai_dsw_config.json')),\n",
    "    (\"数据预处理\", len(glob.glob('data/processed/*.npz')) > 0),\n",
    "    (\"模型训练\", os.path.exists('models/best_model.pt')),\n",
    "    (\"训练历史\", os.path.exists('results/training_history.json')),\n",
    "    (\"模型预测\", os.path.exists('results/evaluation_metrics.json')),\n",
    "    (\"可视化图表\", len(list(Path('results').glob('*.png'))) > 0 if Path('results').exists() else False),\n",
    "    (\"ONNX导出\", os.path.exists('models/model.onnx'))\n",
    "]\n",
    "\n",
    "completed = 0\n",
    "for task, status in checks:\n",
    "    status_icon = \"✅\" if status else \"❌\"\n",
    "    print(f\"{status_icon} {task}\")\n",
    "    if status:\n",
    "        completed += 1\n",
    "\n",
    "completion_rate = completed / len(checks) * 100\n",
    "print(f\"\\n📈 项目完成度: {completion_rate:.1f}% ({completed}/{len(checks)})\")\n",
    "\n",
    "if completion_rate == 100:\n",
    "    print(\"\\n🎉 恭喜! 项目已完整部署并运行成功!\")\n",
    "elif completion_rate >= 70:\n",
    "    print(\"\\n👍 项目主要功能已完成，可以继续优化\")\n",
    "else:\n",
    "    print(\"\\n⚠️  项目仍有部分功能需要完善\")\n",
    "\n",
    "# 显示重要文件路径\n",
    "print(\"\\n📁 重要文件位置:\")\n",
    "important_files = [\n",
    "    'models/best_model.pt',\n",
    "    'models/model.onnx', \n",
    "    'results/evaluation_metrics.json',\n",
    "    'results/training_history.json',\n",
    "    'pai_dsw_config.json'\n",
    "]\n",
    "\n",
    "for file_path in important_files:\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path) / 1024\n",
    "        if file_size > 1024:\n",
    "            print(f\"  ✅ {file_path} ({file_size/1024:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"  ✅ {file_path} ({file_size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ❌ {file_path} (不存在)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eff4c3",
   "metadata": {},
   "source": [
    "## 📚 后续操作建议\n",
    "\n",
    "### 模型优化\n",
    "1. **超参数调优**: 修改 `configs/lstm_transformer.yaml` 中的参数\n",
    "2. **数据增强**: 在 `src/data/preprocess.py` 中添加数据增强策略\n",
    "3. **模型架构**: 在 `src/models/` 中尝试不同的模型结构\n",
    "\n",
    "### 生产部署\n",
    "1. **ONNX推理**: 使用导出的ONNX模型进行高效推理\n",
    "2. **批量预测**: 运行 `src/inference/batch_predict.py` 进行批量处理\n",
    "3. **结果分析**: 使用 `src/inference/analyze_results.py` 进行深入分析\n",
    "\n",
    "### 监控和维护\n",
    "1. **性能监控**: 定期检查模型性能指标\n",
    "2. **数据漂移**: 监控输入数据的分布变化\n",
    "3. **模型更新**: 根据新数据定期重训练模型\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 恭喜! 您已成功在PAI-DSW环境中部署了LSTM+Transformer工业时序预测模型!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
