{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a009cd1",
   "metadata": {},
   "source": [
    "# LSTM+Transformer å·¥ä¸šæ—¶åºé¢„æµ‹æ¨¡å‹ - PAI-DSW å¿«é€Ÿå¯åŠ¨\n",
    "\n",
    "æœ¬Notebookæä¾›äº†åœ¨PAI-DSWç¯å¢ƒä¸­å¿«é€Ÿéƒ¨ç½²å’Œè¿è¡ŒLSTM+Transformeræ—¶åºé¢„æµ‹æ¨¡å‹çš„å®Œæ•´æµç¨‹ã€‚\n",
    "\n",
    "## ğŸ“‹ è¿è¡Œç¯å¢ƒè¦æ±‚\n",
    "- PAI-DSWå®ä¾‹ (æ¨èGPUå®ä¾‹)\n",
    "- Python 3.8+\n",
    "- CUDAæ”¯æŒ (æ¨è)\n",
    "\n",
    "## ğŸš€ å¿«é€Ÿå¼€å§‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a725cc",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒåˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥å½“å‰ç¯å¢ƒ\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"Pythonç‰ˆæœ¬: {sys.version}\")\n",
    "\n",
    "# è®¾ç½®PAI-DSWç¯å¢ƒ\n",
    "if os.path.exists('/mnt/workspace'):\n",
    "    os.chdir('/mnt/workspace')\n",
    "    sys.path.insert(0, '/mnt/workspace')\n",
    "    print(\"âœ… PAI-DSWç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸  æœªæ£€æµ‹åˆ°PAI-DSWç¯å¢ƒï¼Œä½¿ç”¨å½“å‰ç›®å½•\")\n",
    "\n",
    "print(f\"å·¥ä½œç›®å½•: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå®Œæ•´çš„ç¯å¢ƒåˆå§‹åŒ–\n",
    "print(\"ğŸš€ å¼€å§‹ç¯å¢ƒåˆå§‹åŒ–...\")\n",
    "exec(open('setup_pai_dsw.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11886ad6",
   "metadata": {},
   "source": [
    "## 2. æ£€æŸ¥GPUå’Œæ·±åº¦å­¦ä¹ ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥PyTorchå’ŒCUDA\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "    # æµ‹è¯•GPU\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.randn(1000, 1000).to(device)\n",
    "    y = torch.randn(1000, 1000).to(device)\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"âœ… GPUæµ‹è¯•é€šè¿‡\")\n",
    "else:\n",
    "    print(\"âš ï¸  å°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc96c60",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f76141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥æ•°æ®æ–‡ä»¶\n",
    "import glob\n",
    "\n",
    "print(\"ğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶...\")\n",
    "data_paths = [\n",
    "    'data/raw/*.csv',\n",
    "    'data/*.csv',\n",
    "    '/mnt/workspace/data/*.csv'\n",
    "]\n",
    "\n",
    "data_files = []\n",
    "for path in data_paths:\n",
    "    files = glob.glob(path)\n",
    "    data_files.extend(files)\n",
    "\n",
    "if data_files:\n",
    "    print(\"âœ… å‘ç°æ•°æ®æ–‡ä»¶:\")\n",
    "    for file in data_files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ•°æ®æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(data_files[0])\n",
    "    print(f\"\\næ•°æ®é›†ä¿¡æ¯:\")\n",
    "    print(f\"  å½¢çŠ¶: {df.shape}\")\n",
    "    print(f\"  åˆ—å: {list(df.columns)}\")\n",
    "    print(f\"  å‰5è¡Œ:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"âŒ æœªå‘ç°æ•°æ®æ–‡ä»¶!\")\n",
    "    print(\"è¯·ä¸Šä¼ CSVæ ¼å¼çš„è®­ç»ƒæ•°æ®åˆ°ä»¥ä¸‹ç›®å½•ä¹‹ä¸€:\")\n",
    "    print(\"  - data/raw/\")\n",
    "    print(\"  - data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfa8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œæ•°æ®é¢„å¤„ç† (å¦‚æœæ•°æ®æ–‡ä»¶å­˜åœ¨)\n",
    "if data_files:\n",
    "    print(\"ğŸ“Š å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
    "    !python src/data/preprocess.py\n",
    "    print(\"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ!\")\n",
    "else:\n",
    "    print(\"âš ï¸  è·³è¿‡æ•°æ®é¢„å¤„ç† - è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b5ac7",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥é…ç½®æ–‡ä»¶\n",
    "import yaml\n",
    "\n",
    "config_path = 'configs/lstm_transformer.yaml'\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ\")\n",
    "    print(f\"æ¨¡å‹é…ç½®: {config['model']}\")\n",
    "    print(f\"è®­ç»ƒé…ç½®: {config['training']}\")\n",
    "else:\n",
    "    print(f\"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¼€å§‹æ¨¡å‹è®­ç»ƒ (è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "if data_files and os.path.exists(config_path):\n",
    "    print(\"ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...\")\n",
    "    print(\"æ³¨æ„: è®­ç»ƒå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # è¿è¡Œè®­ç»ƒ\n",
    "    result = subprocess.run([\n",
    "        'python', 'src/training/train.py', \n",
    "        '--config', config_path\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"è®­ç»ƒè€—æ—¶: {training_time/60:.1f} åˆ†é’Ÿ\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥:\")\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print(\"âš ï¸  è·³è¿‡æ¨¡å‹è®­ç»ƒ - è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05061b9d",
   "metadata": {},
   "source": [
    "## 5. è®­ç»ƒè¿›åº¦ç›‘æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®æ—¶æŸ¥çœ‹è®­ç»ƒå†å²\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "history_path = 'results/training_history.json'\n",
    "if os.path.exists(history_path):\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0, 0].set_title('Loss Curves')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # MAE curves\n",
    "    axes[0, 1].plot(history['train_mae'], label='Train MAE')\n",
    "    axes[0, 1].plot(history['val_mae'], label='Val MAE')\n",
    "    axes[0, 1].set_title('MAE Curves')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # RÂ² curves\n",
    "    if 'train_r2' in history:\n",
    "        axes[1, 0].plot(history['train_r2'], label='Train RÂ²')\n",
    "        axes[1, 0].plot(history['val_r2'], label='Val RÂ²')\n",
    "        axes[1, 0].set_title('RÂ² Curves')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning rate\n",
    "    if 'learning_rate' in history:\n",
    "        axes[1, 1].plot(history['learning_rate'], label='Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ˜¾ç¤ºæœ€ä½³æŒ‡æ ‡\n",
    "    print(\"ğŸ† è®­ç»ƒç»“æœæ‘˜è¦:\")\n",
    "    print(f\"æœ€ç»ˆè®­ç»ƒLoss: {history['train_loss'][-1]:.6f}\")\n",
    "    print(f\"æœ€ç»ˆéªŒè¯Loss: {history['val_loss'][-1]:.6f}\")\n",
    "    print(f\"æœ€ä½³éªŒè¯MAE: {min(history['val_mae']):.6f}\")\n",
    "    if 'val_r2' in history:\n",
    "        print(f\"æœ€ä½³éªŒè¯RÂ²: {max(history['val_r2']):.6f}\")\n",
    "else:\n",
    "    print(\"âš ï¸  è®­ç»ƒå†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c2506",
   "metadata": {},
   "source": [
    "## 6. æ¨¡å‹é¢„æµ‹å’Œè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55209ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "model_path = 'models/best_model.pt'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"âœ… å‘ç°è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶ä¿¡æ¯\n",
    "    model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"æ¨¡å‹æ–‡ä»¶å¤§å°: {model_size:.2f} MB\")\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹ä¿¡æ¯\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"è®­ç»ƒè½®æ•°: {checkpoint['epoch']}\")\n",
    "    if 'val_loss' in checkpoint:\n",
    "        print(f\"éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}\")\n",
    "    if 'val_mae' in checkpoint:\n",
    "        print(f\"éªŒè¯MAE: {checkpoint['val_mae']:.6f}\")\n",
    "else:\n",
    "    print(\"âŒ æœªå‘ç°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œæ¨¡å‹é¢„æµ‹\n",
    "if os.path.exists(model_path):\n",
    "    print(\"ğŸ”® å¼€å§‹æ¨¡å‹é¢„æµ‹...\")\n",
    "    \n",
    "    !python src/inference/predict.py \\\n",
    "        --config configs/lstm_transformer.yaml \\\n",
    "        --model_path models/best_model.pt \\\n",
    "        --datasets test \\\n",
    "        --generate_viz\n",
    "    \n",
    "    print(\"âœ… æ¨¡å‹é¢„æµ‹å®Œæˆ!\")\n",
    "else:\n",
    "    print(\"âš ï¸  è·³è¿‡æ¨¡å‹é¢„æµ‹ - è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea5b90",
   "metadata": {},
   "source": [
    "## 7. ç»“æœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹é¢„æµ‹ç»“æœå¯è§†åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path('results')\n",
    "if results_dir.exists():\n",
    "    # æŸ¥æ‰¾å¯è§†åŒ–å›¾ç‰‡\n",
    "    viz_files = list(results_dir.glob('*.png'))\n",
    "    \n",
    "    if viz_files:\n",
    "        print(f\"ğŸ“Š å‘ç° {len(viz_files)} ä¸ªå¯è§†åŒ–æ–‡ä»¶:\")\n",
    "        \n",
    "        # æ˜¾ç¤ºé¢„æµ‹ç»“æœå›¾\n",
    "        for viz_file in viz_files[:4]:  # æ˜¾ç¤ºå‰4ä¸ªå›¾ç‰‡\n",
    "            print(f\"\\nğŸ“ˆ {viz_file.name}:\")\n",
    "            \n",
    "            try:\n",
    "                from IPython.display import Image, display\n",
    "                display(Image(str(viz_file)))\n",
    "            except:\n",
    "                print(f\"å›¾ç‰‡è·¯å¾„: {viz_file}\")\n",
    "    else:\n",
    "        print(\"âŒ æœªå‘ç°å¯è§†åŒ–æ–‡ä»¶\")\n",
    "else:\n",
    "    print(\"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½å¹¶æ˜¾ç¤ºé¢„æµ‹æŒ‡æ ‡\n",
    "metrics_path = 'results/evaluation_metrics.json'\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"ğŸ“Š é¢„æµ‹è¯„ä¼°æŒ‡æ ‡:\")\n",
    "    for dataset_name, dataset_metrics in metrics.items():\n",
    "        print(f\"\\n{dataset_name.upper()} æ•°æ®é›†:\")\n",
    "        for metric_name, value in dataset_metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                if metric_name in ['mape', 'smape']:\n",
    "                    print(f\"  {metric_name.upper()}: {value:.2f}%\")\n",
    "                elif metric_name == 'r2':\n",
    "                    print(f\"  {metric_name.upper()}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {metric_name.upper()}: {value:.6f}\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯„ä¼°æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc8b3f",
   "metadata": {},
   "source": [
    "## 8. ONNXæ¨¡å‹å¯¼å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºONNXæ¨¡å‹\n",
    "if os.path.exists(model_path):\n",
    "    print(\"ğŸ“¦ å¼€å§‹ONNXæ¨¡å‹å¯¼å‡º...\")\n",
    "    \n",
    "    !python src/inference/export_onnx.py \\\n",
    "        --model_path models/best_model.pt \\\n",
    "        --output_path models/model.onnx \\\n",
    "        --batch_size 1 \\\n",
    "        --sequence_length 96 \\\n",
    "        --input_size 1\n",
    "    \n",
    "    # æ£€æŸ¥ONNXæ–‡ä»¶\n",
    "    onnx_path = 'models/model.onnx'\n",
    "    if os.path.exists(onnx_path):\n",
    "        onnx_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "        print(f\"âœ… ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ!\")\n",
    "        print(f\"ONNXæ–‡ä»¶å¤§å°: {onnx_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"âŒ ONNXæ¨¡å‹å¯¼å‡ºå¤±è´¥\")\n",
    "else:\n",
    "    print(\"âš ï¸  è·³è¿‡ONNXå¯¼å‡º - è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebb62c",
   "metadata": {},
   "source": [
    "## 9. é¡¹ç›®æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¹ç›®å®Œæˆåº¦æ£€æŸ¥\n",
    "print(\"ğŸ¯ é¡¹ç›®å®Œæˆåº¦æ£€æŸ¥:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "checks = [\n",
    "    (\"ç¯å¢ƒåˆå§‹åŒ–\", os.path.exists('pai_dsw_config.json')),\n",
    "    (\"æ•°æ®é¢„å¤„ç†\", len(glob.glob('data/processed/*.npz')) > 0),\n",
    "    (\"æ¨¡å‹è®­ç»ƒ\", os.path.exists('models/best_model.pt')),\n",
    "    (\"è®­ç»ƒå†å²\", os.path.exists('results/training_history.json')),\n",
    "    (\"æ¨¡å‹é¢„æµ‹\", os.path.exists('results/evaluation_metrics.json')),\n",
    "    (\"å¯è§†åŒ–å›¾è¡¨\", len(list(Path('results').glob('*.png'))) > 0 if Path('results').exists() else False),\n",
    "    (\"ONNXå¯¼å‡º\", os.path.exists('models/model.onnx'))\n",
    "]\n",
    "\n",
    "completed = 0\n",
    "for task, status in checks:\n",
    "    status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"{status_icon} {task}\")\n",
    "    if status:\n",
    "        completed += 1\n",
    "\n",
    "completion_rate = completed / len(checks) * 100\n",
    "print(f\"\\nğŸ“ˆ é¡¹ç›®å®Œæˆåº¦: {completion_rate:.1f}% ({completed}/{len(checks)})\")\n",
    "\n",
    "if completion_rate == 100:\n",
    "    print(\"\\nğŸ‰ æ­å–œ! é¡¹ç›®å·²å®Œæ•´éƒ¨ç½²å¹¶è¿è¡ŒæˆåŠŸ!\")\n",
    "elif completion_rate >= 70:\n",
    "    print(\"\\nğŸ‘ é¡¹ç›®ä¸»è¦åŠŸèƒ½å·²å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  é¡¹ç›®ä»æœ‰éƒ¨åˆ†åŠŸèƒ½éœ€è¦å®Œå–„\")\n",
    "\n",
    "# æ˜¾ç¤ºé‡è¦æ–‡ä»¶è·¯å¾„\n",
    "print(\"\\nğŸ“ é‡è¦æ–‡ä»¶ä½ç½®:\")\n",
    "important_files = [\n",
    "    'models/best_model.pt',\n",
    "    'models/model.onnx', \n",
    "    'results/evaluation_metrics.json',\n",
    "    'results/training_history.json',\n",
    "    'pai_dsw_config.json'\n",
    "]\n",
    "\n",
    "for file_path in important_files:\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path) / 1024\n",
    "        if file_size > 1024:\n",
    "            print(f\"  âœ… {file_path} ({file_size/1024:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"  âœ… {file_path} ({file_size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  âŒ {file_path} (ä¸å­˜åœ¨)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eff4c3",
   "metadata": {},
   "source": [
    "## ğŸ“š åç»­æ“ä½œå»ºè®®\n",
    "\n",
    "### æ¨¡å‹ä¼˜åŒ–\n",
    "1. **è¶…å‚æ•°è°ƒä¼˜**: ä¿®æ”¹ `configs/lstm_transformer.yaml` ä¸­çš„å‚æ•°\n",
    "2. **æ•°æ®å¢å¼º**: åœ¨ `src/data/preprocess.py` ä¸­æ·»åŠ æ•°æ®å¢å¼ºç­–ç•¥\n",
    "3. **æ¨¡å‹æ¶æ„**: åœ¨ `src/models/` ä¸­å°è¯•ä¸åŒçš„æ¨¡å‹ç»“æ„\n",
    "\n",
    "### ç”Ÿäº§éƒ¨ç½²\n",
    "1. **ONNXæ¨ç†**: ä½¿ç”¨å¯¼å‡ºçš„ONNXæ¨¡å‹è¿›è¡Œé«˜æ•ˆæ¨ç†\n",
    "2. **æ‰¹é‡é¢„æµ‹**: è¿è¡Œ `src/inference/batch_predict.py` è¿›è¡Œæ‰¹é‡å¤„ç†\n",
    "3. **ç»“æœåˆ†æ**: ä½¿ç”¨ `src/inference/analyze_results.py` è¿›è¡Œæ·±å…¥åˆ†æ\n",
    "\n",
    "### ç›‘æ§å’Œç»´æŠ¤\n",
    "1. **æ€§èƒ½ç›‘æ§**: å®šæœŸæ£€æŸ¥æ¨¡å‹æ€§èƒ½æŒ‡æ ‡\n",
    "2. **æ•°æ®æ¼‚ç§»**: ç›‘æ§è¾“å…¥æ•°æ®çš„åˆ†å¸ƒå˜åŒ–\n",
    "3. **æ¨¡å‹æ›´æ–°**: æ ¹æ®æ–°æ•°æ®å®šæœŸé‡è®­ç»ƒæ¨¡å‹\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œ! æ‚¨å·²æˆåŠŸåœ¨PAI-DSWç¯å¢ƒä¸­éƒ¨ç½²äº†LSTM+Transformerå·¥ä¸šæ—¶åºé¢„æµ‹æ¨¡å‹!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
